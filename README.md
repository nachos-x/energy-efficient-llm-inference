# Energy-Efficient LLM Inference Pipeline
"Energy-efficient DistilBERT inference pipeline: 8-bit quantization for 74% faster inference & 65% energy reduction. Includes adversarial training, FastAPI + Docker."
